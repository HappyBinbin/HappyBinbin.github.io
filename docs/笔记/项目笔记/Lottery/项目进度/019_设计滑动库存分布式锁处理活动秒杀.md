# 设计滑动库存分布式锁处理活动秒杀

分支：20220405_happy_redis

描述：引入 Redis 到抽奖系统，设计颗粒度更细的滑动库存编号分布式锁，处理活动秒杀流程

## 开发日志

- 在抽奖系统中引入 Redis 模块，优化用户参与抽奖活动。因为只要有大量的用户参与抽奖，那么这个就属于秒杀场景。所以需要使用 Redis 分布式锁的方式来处理集中化库存扣减的问题，否则在 TPS 达到1k-2k，就会把数据库拖垮
- 在设计秒杀流程时，优化锁的粒度，不要把锁直接放到活动编号上，这样在极端临界情况下会出现秒杀解锁失败，导致库存有剩余但不能下单的情况，所以需要减小锁的粒度，以活动库存剩余编号的方式进行加锁，例如 100001_1、100001_2、100001_3，以此类推，具体看代码实现
- 增加缓存扣减库存后，发送 MQ 消息进行异步更新数据库中活动库存，做最终数据一致性处理。这一部分如果你的系统并发体量较大， MQ 的数据不能直接对库更新，而是更新到缓存中，再由任务最阶段同步，以此减少对数据库表的操作

## 扣减流程

![image-20220406191205858](https://happychan.oss-cn-shenzhen.aliyuncs.com/img/pic/202204061912051.png)

- 优化活动领域，活动参与流程中的库存扣减操作，这部分我们原来是使用数据库行级锁🔐 处理的库存扣减，但因为会存在并发问题所以这里优化为 Redis 分布式锁进行处理
- 活动领取完成后，其实这个时候只是把缓存的库存扣掉了，但数据库中的库存并没有扣减，所以我们需要发送一个 MQ 消息，来对数据库中的库存进行处理。因为 MQ 可以消峰因此在降低 MQ 分片的情况下，消费效率有所下降，并不会对数据库造成压力，保证最终数据一致性即可。但也有例外，所以我们提到可以使用定时任务来更新数据库库存

## 功能开发

### 滑块库存锁设计

![image-20220406191405937](https://happychan.oss-cn-shenzhen.aliyuncs.com/img/pic/202204061914259.png)

- 如图所示，即使是使用 Redis 分布式锁，我们也不希望把锁的颗粒度放的太粗，否则还是会出现活动有库存但不能秒杀，提示“活动过于火爆”
- 那么我们就需要按照活动编号把库存锁的颗粒度缩小，实际操作也并不复杂，只是把`活动ID+库存扣减后的值`一起作为分布式锁的Key，这样就缩小了锁的颗粒度

### 滑块库存锁实现

在活动领域层的领取活动抽象类 `BaseActivityPartake` 添加方法 subtractionActivityStockByRedis、recoverActivityCacheStockByRedis，分别用户 Redis 库存扣减和加锁 Key 的处理

#### 库存扣减操作

**ActivityRepository#subtractionActivityStockByRedis**

```java
@Override
public StockResult subtractionActivityStockByRedis(String uId, Long activityId, Integer stockCount) {

    //  1. 获取抽奖活动库存 Key
    String stockKey = Constants.RedisKey.KEY_LOTTERY_ACTIVITY_STOCK_COUNT(activityId);

    // 2. 扣减库存，目前占用库存数
    Integer stockUsedCount = (int) redisUtil.incr(stockKey, 1);

    // 3. 超出库存判断，进行恢复原始库存
    if (stockUsedCount > stockCount) {
        redisUtil.decr(stockKey, 1);
        return new StockResult(Constants.ResponseCode.UN_ERROR.getCode(), Constants.ResponseCode.UN_ERROR.getInfo());
    }

    // 4. 以活动库存占用编号，生成对应加锁Key，细化锁的颗粒度
    String stockTokenKey = Constants.RedisKey.KEY_LOTTERY_ACTIVITY_STOCK_COUNT_TOKEN(activityId, stockUsedCount);

    // 5. 使用 Redis.setNx 加一个分布式锁
    boolean lockToken = redisUtil.setNx(stockTokenKey, 350L);
    if (!lockToken) {
        logger.info("抽奖活动{}用户秒杀{}扣减库存，分布式锁失败：{}", activityId, uId, stockTokenKey);
        return new StockResult(Constants.ResponseCode.UN_ERROR.getCode(), Constants.ResponseCode.UN_ERROR.getInfo());
    }
    return new StockResult(Constants.ResponseCode.SUCCESS.getCode(), Constants.ResponseCode.SUCCESS.getInfo(), stockTokenKey, stockCount - stockUsedCount);
}
```

- 代码中的注释就是整个操作流程，创建 Key、占用库存、判断库存、**以占用库存的编号做为加锁key**、调用 setNx 加一个分布式锁，最终完成整个秒杀扣减库存的动作
- 这里还有一些其他的实现方式，例如：`lua脚本`、zk、jvm层，都可以处理，但经过验证 lua脚本会有一定的耗时，并发较高时会有问题
- 秒杀的设计原则是保证不超卖，但不一定保证100个库存完全消耗掉，因为可能会有一些锁失败的情况。不过在库存数据最终一致性任务处理下，基本保证`3个9`到`4个9`的可用率还是没问题的
- 如果说你的库存秒杀tps已经到10级以上，*一般单key在10万以下是可靠的*，那么这个时候就需要进行库存分片，把路由是思想用到 Redis 使用上，不同的用户进入 Redis 进行秒杀处理时，把他的库存操作路由到属于他的分组上进行处理，那么这样就可以横向扩展了

#### 并发锁删除处理

```java
@Override
public void recoverActivityCacheStockByRedis(Long activityId, String tokenKey, String code) {
    // 删除分布式锁 Key
    redisUtil.del(tokenKey);
}
```

- 秒杀完毕后，接下来的流程是用户记录落库，但可能这个时候会发生失败的情况，因为需要在失败时恢复缓存的库存。不过这个情况不是事务性的，因此可能会恢复失败，也就是保证不超卖，但不能保证一定完全消耗库存。*当然这个部分具体看你希望的是什么，比如你可以牺牲掉一些性能，考虑 lua 脚本和给整个流程分布式事务锁。*
- 如果最后的操作是成功的，那么正常删除掉这个加锁的 Key 就可以了，因为下一个用户获取的到的库存滑块又是新的了，旧 Key 已经没有用了

### 活动秒杀流程处理

![image-20220406191639052](https://happychan.oss-cn-shenzhen.aliyuncs.com/img/pic/202204061916251.png)

- 在领取活动的模板方法中，优化掉原来直接使用数据库行级锁的流程，把 Redis 库存的扣减添加到这里
- 扣减库存后，在各个以下的流程节点中，如果有流程失败则进行缓存库存的恢复操作

### 发送MQ消息，处理数据一致性

由于我们使用 Redis 代替数据库库存，那么在缓存的库存处理后，还需要把数据库中的库存处理为何缓存一致，这样在后续运营这部分数据时才能保证一定的运营可靠性

**ActivityProcessImpl#doDrawProcess**

![image-20220406191712602](https://happychan.oss-cn-shenzhen.aliyuncs.com/img/pic/202204061917729.png)

- 申请新的 MQ Topic：`bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic lottery_activity_partake`
- 这里需要注意，MQ 的发送，只发生在用户首次领取活动时，如果是已经领取活动但因为抽奖等流程失败，二次进入此流程，则不会发送 MQ 消息

### 活动领取记录MQ消费

**LotteryActivityPartakeRecordListener**

```java
@KafkaListener(topics = "lottery_activity_partake", groupId = "lottery")
public void onMessage(ConsumerRecord<?, ?> record, Acknowledgment ack, @Header(KafkaHeaders.RECEIVED_TOPIC) String topic) {
    Optional<?> message = Optional.ofNullable(record.value());
    // 1. 判断消息是否存在
    if (!message.isPresent()) {
        return;
    }
    // 2. 转化对象（或者你也可以重写Serializer<T>）
    ActivityPartakeRecordVO activityPartakeRecordVO = JSON.parseObject((String) message.get(), ActivityPartakeRecordVO.class);
    logger.info("消费MQ消息，异步扣减活动库存 message：{}", message.get());
    
    // 3. 更新数据库库存
    activityPartake.updateActivityStock(activityPartakeRecordVO);
}
```

- 消费 MQ 消息的流程就比较简单了，接收到 MQ 进行更新数据库处理即可。不过我们这里更新数据库并不是直接对数据库进行库存扣减操作，而是把从缓存拿到的库存最新镜像更新到数据库中。它的 SQL = `UPDATE activity SET stock_surplus_count = #{stockSurplusCount} WHERE activity_id = #{activityId} AND stock_surplus_count > #{stockSurplusCount}`
- 更新数据库库存【实际场景业务体量较大，可能也会由于MQ消费引起并发，对数据库产生压力，所以如果并发量较大，可以把库存记录缓存中，并使用定时任务进行处理缓存和数据库库存同步，减少对数据库的操作次数】

## 功能测试

- 确保：kafka 开启、xxl-job 开启、redis 服务开启
- 确保：活动状态可用、活动库存充足、活动时间有效

**单元测试**

**ActivityProcessTest#test_doDrawProcess**

```java
@Test
public void test_doDrawProcess() {
    DrawProcessReq req = new DrawProcessReq();
    req.setuId("xiaofuge");
    req.setActivityId(100001L);
    DrawProcessResult drawProcessResult = activityProcess.doDrawProcess(req);
    logger.info("请求入参：{}", JSON.toJSONString(req));
    logger.info("测试结果：{}", JSON.toJSONString(drawProcessResult));
}
```

- 这里你需要保证测试的用户 ID 还有剩余参与活动的次数，否则不能正常参与抽奖活动。

**测试结果**

```java
2022-04-06 19:02:17.062  INFO 1676 --- [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: Ixf3ykPhT5O_T1ecCmsY_A
2022-04-06 19:02:17.200  INFO 1676 --- [           main] c.h.l.d.s.s.draw.impl.DrawExecImpl       : 执行抽奖策略 strategyId：10001，无库存排除奖品列表ID集合 awardIdList：["1"]
2022-04-06 19:02:17.248  INFO 1676 --- [           main] c.h.l.d.s.service.draw.AbstractDrawBase  : 执行策略抽奖完成【已中奖】，用户：fustack 策略ID：10001 奖品ID：3 奖品名称：ipad
2022-04-06 19:02:17.255  INFO 1676 --- [           main] c.h.m.d.r.s.i.DBRouterStrategyHashCode   : 数据库路由 dbIdx: 2 tbIdx: 0
2022-04-06 19:02:17.332  INFO 1676 --- [           main] c.h.l.a.mq.producer.KafkaProducer        : 发送MQ消息(中奖发货单) topic：lottery_invoice bizId：fustack message：{"awardContent":"Code","awardId":"3","awardName":"ipad","awardType":1,"orderId":1511660559144263680,"uId":"fustack"}
2022-04-06 19:02:17.346  INFO 1676 --- [           main] c.h.l.t.application.ActivityProcessTest  : 请求入参：{"activityId":100001,"uId":"fustack"}
2022-04-06 19:02:17.358  INFO 1676 --- [ad | producer-1] c.h.m.d.r.s.i.DBRouterStrategyHashCode   : 数据库路由 dbIdx: 2 tbIdx: 0
2022-04-06 19:02:17.375  INFO 1676 --- [           main] c.h.l.t.application.ActivityProcessTest  : 测试结果：{"code":"0000","drawAwardVO":{"awardContent":"Code","awardId":"3","awardName":"ipad","awardType":1,"grantType":1,"strategyMode":2,"uId":"fustack"},"info":"成功"}
```

- 从测试结果已经可以看到，异步扣减库存的流程已经生效，同时你可以去检查数据库中活动库存是否已经异步更新。*因为我们有一个更新条件判断是否更新数据比剩余库存数据最新，否则不会更新*

## 总结

------

1. 学习 Redis 云服务环境配置，至少可以知道需要配置哪些内容，才可以让你的本地环境访问到 Redis 云服务
2. 熟知分布式锁的颗粒度可以细化的设计，这在你以后的使用流程中，都可以作为参考
3. 对数据最终一致性有一个基本概念，它是不是强流程、什么时候更新、怎么用 MQ 进行消峰，以避免拖垮数据库
4. 学习整个设计以及对流程的把握，一点合理的设计，在将来的代码维护中，都将发挥巨大的价值



## 问题与思考

1、为啥这里要进行上锁啊，那个上锁的key不是通过递增得到的吗，应该不会有两个客户端得到同一个key吧。 而且，在递增stockKey之后，会进行库存的判断，如果大于了库存就直接返回了

![image-20220404061106167](https://happychan.oss-cn-shenzhen.aliyuncs.com/img/pic/202204040611336.png)

其实如果只是增加，不使用锁也可以。后面还有一个回滚操作，两个都是原子的，但是需要在一个锁下才有事务的特性



2、这个方法传入的参数是库存总数，然后递增和总数进行判断，不是应该和剩余库存stockSurplusCount 进行判断吗，而不是库存总数

递增不是和总的对比吗？剩余 > 0 就可以用。那递增和剩余的怎么比，这个你可以调试下



3、 如果业务要求事务的一致性比较强，如果更改业务流程？

- lua 脚本 或者 分布式流程锁
