## 项目介绍

![image-20220219114319218](https://gitee.com/HappyBinbin/pcigo/raw/master/image-20220219114319218.png)

## 技术问答

Q：

- 抽奖系统的服务是怎么划分的，划分成了哪些服务，怎么做分布式的部署。？
- 这个项目能抗住多大的并发？

A：

1. 抽奖系统是占营销活动系统的一部分，整条链路基础的包括：一组核心业务系统(比如：商城、论坛、游戏都可以)、用户系统、账户系统、奖品系统。
2. 流程上可以通过抽奖单对用户的积分账号进行扣减消耗，进行抽奖，抽奖完成后，进行奖品发放。PS：抽奖也可以类比商城下单；订单号、支付单、交易单、发货。 
3. 分布式部署，从用户系统、账户系统、抽奖系统、奖品系统等都部署多套，系统间使用 RPC 进行通信，对外网关层使用 HTTP 进行通信。 
4. QPS 可以说是日常均值500-1000，活动运营集中push推送，峰值可达3000-5000 持续半分钟左右。

Q：

- 在实际项目中，redis 和 zookeeper 实现分布式锁，哪个使用的多，为什么？各自有什么优缺点，为什么抽象系统不用 zookeeper 来实现分布式锁？

A：

1. 从运维成本回答：如果公司已经有一套非常稳定的 Redis 集群，而 ZK 需要自己搭建维护，那么就使用 Redis 
2. 从技术实现回答：目前 Redis 在抽奖系统中使用的分布式锁，是分段滑块锁，降低锁的颗粒度。如果使用 ZK 也实现同样的方案，会需要频繁的创建节点删除节点，性能比不上缓存锁。
3. 从业务场景回答：因为我们的场景是抽奖系统，并不是下单秒杀，可以在一定程度只保证不超卖即可。如果是需要非常强一致性的下单支付类场景，ZK 的加锁稳定性会比 Redis 更可靠一些，不过也可以通过通过加强 Redis 的集群来解决此问题。
4. 综上：以结合实际的业务场景诉求，结合公司实际情况，在最低运维成本下，完成业务需求，降低研发成本，提高交付质量



Q：

- 抽象系统中，如果扣减库存成功了，而后续的步骤因为出现了活动异常的情况，但是这个扣减库存是已经完成，不会再返回的，有什么容错的机制吗？

A：

1. 【背景】其实按照运营来看，是会配置出一定数量的参与抽奖活动，但不会得到奖品的用户
2.  当然可能根据不同的业务诉求，不同的风险级别，有些场景是需要30分钟内未支付/未交易/未抽奖等，进行分布式扫描库表扭转订单/抽奖单状态，恢复库存操作
3. 因为我们这场景是不需要这样的处理，参与失败的用户也证明是参与了，可以进行第二次抽奖，再发起抽奖的时候会查询到以往的抽奖单信息执行抽奖



Q：

- Q1：项目的并发瓶颈在哪？用了什么手段去解决？在未来要进行优化会怎么做？
- Q2：目前我们就是把库存分散到了不同的redis分片中，但是存在一个问题：hash取模得到的redis分片没有库存时，但是其他的分片是有库存的。这块还得考虑迁移到其他分片去扣库存。

A：

1. 早期对于抽奖的库存扣减是依赖于数据库行级锁的，后来因为业务流量较大，优化为 Redis 分布式锁。但因为锁的方式使用的是独占竞态锁，所有流量打到一个 Key 上进行秒杀处理，容易造成死锁风险，后优化为分段竞态锁，降低锁的颗粒度，提供高可用。 
2. 目前我们还实现了 Redis 路由组件，如果未来对于这块的热key、秒杀库存极限等瓶颈问题，还可以把库存数据分散到不同的 Redis 服务中。 
3. 还可以再聊一下延迟发奖的瓶颈，需要指定某个时间点，同时发奖，这里包括了低延迟任务的处理，需要把数据库的任务数据提前预热到Redis进行消费，详细：[方案设计：基于库表分段扫描和数据Redis预热，优化分布式延迟任务触达时效性](https://mp.weixin.qq.com/s/jJ0vxdeKXHiYZLrwDEBOcQ)
4. 会有Q2这种情况，通常会提供一个路由列表，在一个库存消耗尽时，会从路由列表移除，直至全部清空。PS：这里也会配置是否允许动态调整，以满足不同的业务诉求，有些是允许A可以秒杀，B秒杀不到的场景。

