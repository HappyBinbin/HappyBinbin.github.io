时序数据的降采样是指将频率较高的时序数据降低到较低频率的时序数据的过程。降采样可以减少数据量从而延长存储时间，提升查询速度，同时尽可能地保留原始数据的趋势和特征。日志服务的降采样通过将时间序列中的数据点进行特定算法的分组与聚合来实现。

注意：降采样本身并不会减少存储空间
## 降采样原理

![Pasted image 20250808100616.png](https://happychan.oss-cn-shenzhen.aliyuncs.com/picgo/Pasted%20image%2020250808100616.png)


## Compactor

thanos 的降采样核心逻辑在 pkg/compact/downsample，集成在 thanos compact 组件中；
这个压缩器既负责压缩、去重指标，也同时负责降采样；`thanos compact`命令将 Prometheus 2.0 存储引擎的压缩过程应用于对象存储中存储的块数据。


在以给定分辨率进行降采样之前，存在一个时间延迟。这是必要的，因为降采样后的块包含的样本较少，而且由于块的大小是固定的，因此需要跨越更长时间间隔的数据来填充它们。

- Creating 5m downsampling for blocks older than **40 hours** (2d)  
    为超过 **40 小时** （2 天）的区块创建 5 分钟下采样
- Creating 1h downsampling for blocks older than **10 days** (2w)  
    为超过 **10 天**的区块创建 1 小时下采样（2w）

## 降采样

Thanos Compactor 采用“原始”分辨率块，并创建一个包含“降采样”块的新分辨率块。降采样块采用“AggrChunk”的存储级别形式：

``` go
message AggrChunk {
    int64 min_time = 1;
    int64 max_time = 2;

    Chunk raw     = 3;
    Chunk count   = 4;
    Chunk sum     = 5;
    Chunk min     = 6;
    Chunk max     = 7;
    Chunk counter = 8;
}
```

### 降采样的默认查询

当查询降采样后的aggrchunk时，promql中没有指定聚合函数，Thanos Querier 会默认请求 COUNT 和 SUM 聚合块，用来计算平均值；

``` go
// aggrsFromFunc infers aggregates of the underlying data based on the wrapping
// function of a series selection.
func aggrsFromFunc(f string) []storepb.Aggr {
	if f == "min" || strings.HasPrefix(f, "min_") {
		return []storepb.Aggr{storepb.Aggr_MIN}
	}
	if f == "max" || strings.HasPrefix(f, "max_") {
		return []storepb.Aggr{storepb.Aggr_MAX}
	}
	if f == "count" || strings.HasPrefix(f, "count_") {
		return []storepb.Aggr{storepb.Aggr_COUNT}
	}
	// f == "sum" falls through here since we want the actual samples.
	if strings.HasPrefix(f, "sum_") {
		return []storepb.Aggr{storepb.Aggr_SUM}
	}
	if f == "increase" || f == "rate" || f == "irate" || f == "resets" || f == "xincrease" || f == "xrate" {
		return []storepb.Aggr{storepb.Aggr_COUNTER}
	}
	// In the default case, we retrieve count and sum to compute an average.
	return []storepb.Aggr{storepb.Aggr_COUNT, storepb.Aggr_SUM}
}
```

### 当前窗口计算

``` go
// currentWindow returns the end timestamp of the window that t falls into.
func currentWindow(t, r int64) int64 {
	// The next timestamp is the next number after s.t that's aligned with window.
	// We subtract 1 because block ranges are [from, to) and the last sample would
	// go out of bounds otherwise.
	return t - (t % r) + r - 1
}
```

假设分辨率 r 为 5 分钟（300,000 毫秒），时间戳 t 为 1,620,000,001 毫秒：
- 计算 t % r 得到 1 毫秒
- 计算 t - (t % r) 得到 1,620,000,000 毫秒（当前窗口起始时间）
- 加上 r 得到 1,620,300,000 毫秒（下一个窗口起始时间）
- 减 1 得到 1,620,299,999 毫秒（当前窗口结束时间）
这确保了时间窗口  `[1,620,000,000, 1,620,300,000)` 内的所有样本都被正确包含在当前窗口中。

currentWindow 函数的设计是为了满足降采样过程中时间窗口对齐、区间表示适配、批次划分、防止重叠和支持聚合逻辑的需求。通过将时间戳准确对齐到窗口边界，并适配左闭右开的区间表示，确保了降采样数据的准确性和一致性。

## 数据聚合器

thanos 中只有两种聚合器，一个是浮点数、一个是直方图；这两种聚合器，就能够将所有的Prometheus 数据类型都覆盖到：
- 数值型数据 ：最常见的 float64 类型数据，用于表示大多数监控指标,例如：`guage、count`
- 直方图数据 ：用于表示数据分布情况的复杂类型，对性能分析和 SLO 监控至关重要；例如：`histogram、summary`

### thanos simple metric

``` go
type sample struct {
	t  int64                    // 时间戳
	v  float64                  // 浮点数值（用于非直方图样本）
	fh *histogram.FloatHistogram // 浮点直方图（用于直方图样本）
}
```

### 浮点数聚合器

``` go
// floatAggregator collects cumulative stats for a stream of values.
type floatAggregator struct {
	total   int     // Total samples processed.
	count   int     // Samples in current window.
	sum     float64 // Value sum of current window.
	min     float64 // Min of current window.
	max     float64 // Max of current window.
	counter float64 // Total counter state since beginning.
	resets  int     // Number of counter resets since beginning.
	last    float64 // Last added value.
}
```

关键变量说明
- a.total : 已处理的总样本数
- a.counter : 计数器值，用于累计计算
- a.resets : 计数器重置次数
- a.last : 上一个样本的值
- a.sum : 所有样本值的总和
- a.count : 当前聚合窗口内的样本数
- a.min / a.max : 样本中的最小值/最大值

``` go
// 核心方法
func (a *floatAggregator) add(s sample) {
	if a.total > 0 {
		if s.v < a.last {
			// Counter reset, correct the value.
			a.counter += s.v
			a.resets++
		} else {
			// Add delta with last value to the counter.
			a.counter += s.v - a.last
		}
	} else {
		// First sample sets the counter.
		a.counter = s.v
	}
	a.last = s.v

	a.sum += s.v
	a.count++
	a.total++

	if s.v < a.min {
		a.min = s.v
	}
	if s.v > a.max {
		a.max = s.v
	}
}
```

该方法接收一个样本点 s ，并根据样本值和历史状态更新聚合器的内部状态，包括计数器值、总和、计数、最大值、最小值等。
设计理念：
1. 计数器重置检测 : 该方法能够自动检测计数器重置事件(如服务重启导致的计数器归零)，并通过 resets 字段记录，确保聚合结果的准确性
2. 增量计算 : 对于正常增长的计数器，通过计算增量( s.v - a.last )而非直接累加，避免重复计数
3. 多维度统计 : 同时维护总和、计数、最大/最小值等多种统计指标，为降采样提供全面的数据支持
4. 状态维护 : 通过维护 last 和 total 等状态变量，确保跨批次样本处理的连续性

### 直方图聚合器

``` go
type histogramAggregator struct {
	total    int                       // 总共处理的直方图数量
	count    int                       // 当前窗口中的直方图数量
	sum      *histogram.FloatHistogram // 当前窗口的值总和（用于仪表直方图）
	counter  *histogram.FloatHistogram // 自开始以来的总计数器状态（用于计数器直方图）
	previous *histogram.FloatHistogram // 上一个添加的值
	schema   int32                     // 正在聚合的批次中的最小模式
}


```

该方法用于将直方图样本添加到聚合器中进行聚合计算

``` go
func (h *histogramAggregator) add(s sample) {
	fh := s.fh
	// 低分变率无法聚合为高分辨率的指标
	if fh.Schema < h.schema {
		panic("schema must be greater or equal to aggregator schema")
	}

	// A schema increase is treated as a reset, so we need to preserve
	// the original histogram in case the schema is adjusted.
	oFh := fh
	// If schema of the sample is greater than the
	// aggregator schema, we need to reduce the resolution.
	if fh.Schema > h.schema {
		// 通过降分辨率来统一所有样本的精度，确保聚合的一致性
		fh = fh.CopyToSchema(h.schema)
	}

	if h.total > 0 {
		if fh.CounterResetHint != histogram.GaugeType && oFh.DetectReset(h.previous) {
			// Counter reset, correct the value.
			mustHistogramOp(h.counter.Add(fh))
		} else {
			// Add delta with previous value to the counter.
			// 直方图差值计算
			deltaFh, err := fh.Copy().Sub(h.previous)
			if err != nil {
				// TODO(GiedriusS): support native histograms with custom buckets.
				// This can only happen with custom buckets.
				panic(fmt.Sprintf("unexpected error: %v", err))
			}
			// 直方图counter累加
			mustHistogramOp(h.counter.Add(deltaFh))
		}
	} else {
		// First sample sets the counter.
		h.counter = fh.Copy()
	}

	// 直方图求和
	if h.sum == nil {
		h.sum = fh.Copy()
	} else {
		mustHistogramOp(h.sum.Add(fh))
	}

	// This needs to be h gauge histogram, otherwise reset detection will be triggered
	// when appending the aggregated chunk and histogram.count < appender.count.
	h.sum.CounterResetHint = histogram.GaugeType

	h.previous = fh

	h.count++
	h.total++
}
```

设计理念：
1. Schema统一 ：使用 CopyToSchema 确保所有直方图使用相同的分辨率
2. Counter处理 ：
	- 检测counter reset： oFh.DetectReset(h.previous)
	- 如果有reset：直接 h.counter.Add(fh)
	- 如果无reset：计算增量 fh.Copy().Sub(h.previous) 然后累加
3. Sum处理 ：
	- 使用 h.sum.Add(fh) 累加当前窗口的直方图值
4. 状态更新 ：
	- 更新 h.previous 、 h.count 、 h.total 等状态
这种设计确保了直方图数据在降采样过程中既保持了counter的语义（处理reset和增量），又支持gauge的语义（窗口期求和），同时通过schema统一保证了数据的一致性。

## 总结

thanos 的降采样思路：
- 定时（每2h）扫描存储桶中的bucket，然后将延迟一定时长（例如：40h、10d）的 blocks 块进行不同分辨率（5m、1h）的降采样。降采样后的数据也存储在同一个存储桶（会增加存储压力）；
核心算法：
- 每个窗口（windows）分辨率，会保留所有指标的特征值（最大值、最小值、总值、总数等）
- 不同的数据类型有不同的计算规则，但总体思路是一致的
查询适配：
- 在查询引擎中会根据查询语句传入的参数，选择不同的存储引擎，或者不同的分辨率（raw、5m、1h、auto）
- promql 函数适配，因为经过采样，已经保留了指标的特征值，所以很多promql中的功能函数（sum、count、max、min等）都能直接取值，不需要经过计算；当promql中没有传入功能函数时，则会按照平均值进行计算；
- 在查询满足时间范围内的blocks时，会查询出所有分辨率的blocks块，根据传入的分辨率参数，优先查询尽可能大的分辨率，如果当前分辨率无法覆盖所有数据，则使用更高分辨率的块填充

局限性：

> - 依赖 Prometheus v2.2.1 以上
> - 只有配置了对象存储，才能使用 thanos compact 能力；compact 和 downsample 都是基于对象存储的
> - 不具备并发安全性，并且必须针对存储桶部署为单例
> - 需要为Prometheus配置全局的外部标签，区分不同实例的指标，这样压缩器才能正常工作；

