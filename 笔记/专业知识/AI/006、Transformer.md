上文提到，我们利用 RNN 解决了词与词之间的相关性，但它仍然存在缺陷；例如：无法并行计算、长时间步关联会丢失信息等问题。所以，google 的大佬又研究出了一种新的方法，也就是 `Transformer`

## Attention Is All You Need


